{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Expresso-24-October-21.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhUfMCyqPUXY"
      },
      "source": [
        "! pip install catboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P_FkIk7PnvR"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYrA_QsCPsYq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import xgboost as xgb\n",
        "import catboost as cat_\n",
        "import seaborn as sns\n",
        "import lightgbm as lgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK_NQq7UP2vL"
      },
      "source": [
        "class func() :   \n",
        "    def __init__(self, train, label, test, model, model_type, random_state):\n",
        "        self.train, self.label, self.test = train, label, test\n",
        "        self.model, self.model_type = model, model_type\n",
        "        self.random_state = random_state\n",
        "        \n",
        "        assert self.model_type in ('catboost', 'xgboost', 'lgbm'), 'Incorrect model_type'\n",
        "    def __call__(self, plot = True):\n",
        "        return self.fit(plot)\n",
        "\n",
        "    def fit(self, plot):\n",
        "        def catboost_fit(X_train, X_test, y_train, y_test):\n",
        "            self.model.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=500,\n",
        "                           verbose=50,use_best_model=True)\n",
        "            x_test_predict = self.model.predict_proba(X_test)[:,1]\n",
        "            x_train_predict = self.model.predict_proba(X_train)[:,1]\n",
        "            self.val_p[test_index] = x_test_predict\n",
        "            self.test_p += self.model.predict_proba(self.test)[:,1]\n",
        "            return x_test_predict, x_train_predict\n",
        "\n",
        "        def xgboost_fit(X_train, X_test, y_train, y_test):\n",
        "            self.model.fit(X_train, y_train, early_stopping_rounds = 30, eval_metric=\"auc\",\n",
        "                           eval_set=[(X_test, y_test)], verbose = True)\n",
        "            x_test_predict = self.model.predict_proba(X_test, ntree_limit = self.model.get_booster().best_ntree_limit)[:,1]\n",
        "            x_train_predict = self.model.predict_proba(X_train, ntree_limit = self.model.get_booster().best_ntree_limit)[:,1]\n",
        "            self.val_p[test_index] = x_test_predict\n",
        "            self.test_p += self.model.predict_proba(self.test, ntree_limit = self.model.get_booster().best_ntree_limit)[:,1]\n",
        "            return x_test_predict, x_train_predict\n",
        "\n",
        "        def lgbm_fit(X_train, X_test, y_train, y_test):\n",
        "            self.model.fit(X_train, y_train, early_stopping_rounds = 30, eval_metric=\"auc\",\n",
        "                           eval_set=[(X_test, y_test)], verbose = True)\n",
        "            x_test_predict = self.model.predict_proba(X_test, num_iteration = self.model.best_iteration_)[:,1]\n",
        "            x_train_predict = self.model.predict_proba(X_train, num_iteration = self.model.best_iteration_)[:,1]\n",
        "            self.val_p[test_index] = x_test_predict\n",
        "            self.test_p += self.model.predict_proba(self.test, num_iteration = self.model.best_iteration_)[:,1]\n",
        "            return x_test_predict, x_train_predict\n",
        "\n",
        "\n",
        "        self.val_p = np.zeros(self.train.shape[0])\n",
        "        mean_val = []\n",
        "        mean_train = []\n",
        "        self.test_p = np.zeros(self.test.shape[0])\n",
        "        splits = 2\n",
        "        kf = StratifiedKFold(n_splits = splits)\n",
        "        for fold_count, (train_index, test_index) in enumerate(kf.split(self.train, self.label)):\n",
        "            X_train,X_test = self.train.iloc[train_index],self.train.iloc[test_index]\n",
        "            y_train,y_test = self.label.iloc[train_index],self.label.iloc[test_index]\n",
        "\n",
        "            print(f\"================================Fold{fold_count+1}====================================\")\n",
        "            if self.model_type == 'catboost': x_test_predict, x_train_predict = catboost_fit(X_train, X_test, y_train, y_test)\n",
        "            elif self.model_type == 'xgboost': x_test_predict, x_train_predict = xgboost_fit(X_train, X_test, y_train, y_test)\n",
        "            elif self.model_type == 'lgbm': x_test_predict, x_train_predict = lgbm_fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "            print('\\nValidation scores', roc_auc_score(y_test, x_test_predict), log_loss(y_test, x_test_predict))\n",
        "            print('Training scores', roc_auc_score(y_train, x_train_predict), log_loss(y_train, x_train_predict))\n",
        "            mean_val.append(roc_auc_score(y_test, x_test_predict))\n",
        "            mean_train.append(roc_auc_score(y_train, x_train_predict))\n",
        "\n",
        "        if plot:\n",
        "            feat_imp = pd.DataFrame(sorted(zip(self.model.feature_importances_,self.train.columns)), columns=['Value','Feature'])\n",
        "            plt.figure(figsize=(30,25))\n",
        "            sns.barplot(x=\"Value\", y=\"Feature\", data=feat_imp.sort_values(by=\"Value\", ascending=False))\n",
        "            plt.ylabel('Feature Importance Score')\n",
        "            plt.show()\n",
        "        print(np.mean(mean_val), np.mean(mean_train), np.std(mean_val))\n",
        "        return self.val_p, self.test_p/splits, self.model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRzyQbJKP6kg"
      },
      "source": [
        "train = pd.read_csv('/content/gdrive/My Drive/zindiDatasets/expressochurn/Train.csv')\n",
        "test =  pd.read_csv('/content/gdrive/My Drive/zindiDatasets/expressochurn/Test.csv')\n",
        "submission = pd.read_csv('/content/gdrive/My Drive/zindiDatasets/expressochurn/SampleSubmission.csv')\n",
        "vardef = pd.read_csv('/content/gdrive/My Drive/zindiDatasets/expressochurn/VariableDefinitions.csv')\n",
        "\n",
        "def reduce_memory_usage(df, verbose=True):\n",
        "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
        "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type in numerics:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == \"int\":\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:\n",
        "                if (\n",
        "                    c_min > np.finfo(np.float16).min\n",
        "                    and c_max < np.finfo(np.float16).max\n",
        "                ):\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif (\n",
        "                    c_min > np.finfo(np.float32).min\n",
        "                    and c_max < np.finfo(np.float32).max\n",
        "                ):\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
        "    if verbose:\n",
        "        print(\n",
        "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
        "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
        "            )\n",
        "        )\n",
        "    return df\n",
        "\n",
        "\n",
        "train = reduce_memory_usage(train, verbose=True)\n",
        "test = reduce_memory_usage(test, verbose=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnYYwnQRQNLJ"
      },
      "source": [
        "\n",
        "print(train.MRG.value_counts(dropna = False), 'Train length:', len(train), '\\n')\n",
        "print(test.MRG.value_counts(dropna = False), 'Test length:', len(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaoDk7rWQP-S"
      },
      "source": [
        "\n",
        "train.drop(['user_id', 'MRG',], 1, inplace = True)\n",
        "test.drop(['user_id', 'MRG',], 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aWk_s6cQTTw"
      },
      "source": [
        "\n",
        "ntrain = train.shape[0]\n",
        "ntest = test.shape[0]\n",
        "data = pd.concat((train, test)).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-ln4TMrQV4J"
      },
      "source": [
        "data['REVENUE-MONTANT'] = data['REVENUE'] - data['MONTANT']\n",
        "data['REVENUE/MONTANT'] = data['REVENUE'] / data['MONTANT']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPHSQfeUQXys"
      },
      "source": [
        "data['TENURE'] = data['TENURE'].map({'K > 24 month': 24, 'I 18-21 month': 18, 'H 15-18 month': 15, 'G 12-15 month':12,\n",
        "                                             'J 21-24 month': 21, 'F 9-12': 9, 'E 6-9 month':6, 'D 3-6 month':3})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIL5_cVJQZ_c"
      },
      "source": [
        "#RETURN THE AVERAGE OF THE MONTH/TENURE BOUNDARIES\n",
        "data['TENURE_avg'] = data['TENURE'].map({'K > 24 month': (24+27)/2, 'I 18-21 month':(18+21)/2 , 'H 15-18 month': (15+18)/2, 'G 12-15 month':(12+15)/2,\n",
        "                                             'J 21-24 month': (21+24)/2, 'F 9-12': (9+12)/2, 'E 6-9 month':(6+9)/2, 'D 3-6 month':(3+6)/2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvbg7dB7Qcam"
      },
      "source": [
        "data['TENURE/FREQUENCE_RECH'] = data['TENURE_avg'] / data['FREQUENCE_RECH']\n",
        "data['TENURE/REGULARITY'] = data['TENURE_avg'] / data['REGULARITY']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F50VAPxeQejt"
      },
      "source": [
        "\n",
        "region = data.groupby('REGION').mean()\n",
        "region.drop('CHURN', 1, inplace = True)\n",
        "cols = []\n",
        "for i in region.columns:\n",
        "    if i != 'REGION':\n",
        "        region[i+'_reg_mean_all'] = region[i]\n",
        "        region.drop(i, 1, inplace = True)\n",
        "        cols.append(i+'_reg_mean_all')\n",
        "\n",
        "data = pd.merge(data, region, on='REGION', how = 'left')\n",
        "for col in cols: data[col+'_freq'] = data[col].map(data[col].value_counts().to_dict())/len(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xxLQpgbQhXe"
      },
      "source": [
        "data['freq*montant'] = data['FREQUENCE'] * data['MONTANT']\n",
        "data['freq*rech'] = data['FREQUENCE'] * data['FREQUENCE_RECH']\n",
        "data['freq*revenue'] = data['FREQUENCE'] * data['REVENUE']\n",
        "data['freq*segment'] = data['FREQUENCE'] * data['ARPU_SEGMENT']\n",
        "\n",
        "data['freq/montant'] =  data['MONTANT']/ data['FREQUENCE']\n",
        "data['freq/rech'] = data['FREQUENCE'] / data['FREQUENCE_RECH']\n",
        "data['freq/revenue'] = data['FREQUENCE'] / data['REVENUE']\n",
        "data['freq/segment'] = data['FREQUENCE'] / data['ARPU_SEGMENT']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ1Oir-yQlFM"
      },
      "source": [
        "data['data/reg'] = data['DATA_VOLUME'] / data['REGULARITY']\n",
        "data['net/reg'] = data['ON_NET'] / data['REGULARITY']\n",
        "data['montant-rech/freq'] = (data['MONTANT'] - data['FREQUENCE_RECH']) / data['FREQUENCE']\n",
        "data['segment/reg'] = data['ARPU_SEGMENT'] / data['REGULARITY']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRxh4EKjQm1V"
      },
      "source": [
        "data['reg_log'] = np.log1p(data['REGULARITY'])\n",
        "data['rech_log'] = np.log1p(data['FREQUENCE_RECH'])\n",
        "data['data_log'] = np.log1p(data['DATA_VOLUME'])\n",
        "data['montant_log'] = np.log1p(data['MONTANT'])\n",
        "data['rev_log'] = np.log1p(data['REVENUE'])\n",
        "data['freq_log'] = np.log1p(data['FREQUENCE'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95gj7AQ2QpRR"
      },
      "source": [
        "data['reglog-montlog'] = data['reg_log'] - data['montant_log']\n",
        "data['revlog/montlog'] = data['REVENUE'] / data['montant_log']\n",
        "data['tenure/rechlog'] = data['TENURE_avg'] / data['rech_log']\n",
        "data['reglog-datalog'] = data['reg_log'] - data['data_log']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikU1P6seQr__"
      },
      "source": [
        "drop = ['REGION', 'TOP_PACK']\n",
        "data.drop(drop, 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyYOtOPZQt0b"
      },
      "source": [
        "\n",
        "train = data[:ntrain].copy()\n",
        "#train.drop_duplicates(inplace = True, ignore_index=True)\n",
        "target = train.CHURN.copy()\n",
        "train.drop('CHURN', axis=1, inplace=True)\n",
        "\n",
        "test = data[ntrain:].copy()\n",
        "test.drop('CHURN', axis=1, inplace=True)\n",
        "test = test.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thETwtPAQw2p"
      },
      "source": [
        "\n",
        "catboost = cat_.CatBoostClassifier(n_estimators=10000, max_depth=6, eval_metric='AUC', reg_lambda = 370)\n",
        "\n",
        "func_= func(train, target, test, catboost, 'catboost', 1000)\n",
        "val_p1, test_p1, model1 = func_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RFk49ERQz8A"
      },
      "source": [
        "\n",
        "xgboost = xgb.XGBClassifier(objective ='binary:logistic', \n",
        "                          eta = 0.99,\n",
        "                          max_depth = 6, \n",
        "                          n_estimators = 5000,\n",
        "                          reg_lambda = 500,\n",
        "                          sub_sample = 0.8,\n",
        "                          colsample_bytree = 0.8)\n",
        "\n",
        "func_= func(train, target, test, xgboost, 'xgboost', 1000)\n",
        "val_p2, test_p2, model2 = func_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHUB7aYBRBKy"
      },
      "source": [
        "import lightgbm as lgb\n",
        "lgb_model = lgb.LGBMClassifier(objective =  'binary', \n",
        "                            metric= 'auc',\n",
        "                            boosting_type= 'gbdt',\n",
        "                            lambda_l1= 0.0004912993970392775,\n",
        "                            lambda_l2= 9.424350138808432,\n",
        "                            num_leaves= 24,\n",
        "                            feature_fraction= 1.0,\n",
        "                            bagging_fraction= 0.9540416539312312,\n",
        "                            bagging_freq= 7,\n",
        "                            min_child_samples= 100, n_estimators = 300)\n",
        "\n",
        "func_= func(train, target, test, lgb_model, 'lgbm', 1000)\n",
        "val_p3, test_p3, model3 = func_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDaSjomHRNV_"
      },
      "source": [
        "from sklearn.linear_model import  LinearRegression, Ridge, Lasso\n",
        "stack = np.column_stack((val_p1, val_p2, val_p3))\n",
        "stack_p = np.column_stack((test_p1, test_p2, test_p3))\n",
        "predict = LinearRegression().fit(stack, target).predict(stack_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wIWC28ZRVQK"
      },
      "source": [
        "submission['CHURN'] = predict\n",
        "\n",
        "submission.to_csv('final_predictions.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntuvWq1LRZ7d"
      },
      "source": [
        "import pickle \n",
        "# save our modell \n",
        "# Save the trained model as a pickle string. \n",
        "saved_model = pickle.dumps(stack) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72c762owzvey"
      },
      "source": [
        "\n",
        "import joblib\n",
        "joblib.dump(stack, \"expresso_churn.joblib\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIbQkM26gFwH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}